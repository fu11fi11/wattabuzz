import json
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any, Optional
import os
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
import sqlite3
import logging

logger = logging.getLogger(__name__)

class DatabaseManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì
    
    ë‚˜ì¤‘ì— FastAPIë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë•Œë„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë…ë¦½ì ì¸ ëª¨ë“ˆ
    PostgreSQLì„ ì‚¬ìš©í•˜ì—¬ í™•ì¥ì„± ìˆëŠ” ë°ì´í„° ì €ì¥ì†Œ êµ¬ì¶•
    """
    
    def __init__(self, database_url: str = None):
        """ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            database_url: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URL
        """
        from dotenv import load_dotenv
        load_dotenv()
        
        if database_url is None:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°, ì—†ìœ¼ë©´ SQLite ì‚¬ìš©
            database_url = os.getenv('DATABASE_URL', 'sqlite:///data/wattabuzz.db')
        
        self.database_url = database_url
        self.is_postgresql = database_url.startswith('postgresql')
        
        try:
            if self.is_postgresql:
                self.engine = create_engine(database_url, pool_pre_ping=True)
                print("ğŸ˜ PostgreSQL ì—°ê²° ì‹œë„ ì¤‘...")
            else:
                # SQLiteìš© ë””ë ‰í† ë¦¬ ìƒì„±
                if database_url.startswith('sqlite:///'):
                    db_path = database_url.replace('sqlite:///', '')
                    os.makedirs(os.path.dirname(db_path), exist_ok=True)
                self.engine = create_engine(database_url)
                print("ğŸ—ƒï¸ SQLite ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            self._init_database()
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            # SQLiteë¡œ fallback
            fallback_url = 'sqlite:///data/wattabuzz.db'
            print(f"ğŸ”„ SQLiteë¡œ fallback: {fallback_url}")
            
            os.makedirs('data', exist_ok=True)
            self.database_url = fallback_url
            self.is_postgresql = False
            self.engine = create_engine(fallback_url)
            self._init_database()
    
    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
        try:
            with self.engine.connect() as conn:
                with conn.begin():  # íŠ¸ëœì­ì…˜ ì‹œì‘
                    if self.is_postgresql:
                        # PostgreSQL ìŠ¤í‚¤ë§ˆ
                        self._create_postgresql_tables(conn)
                    else:
                        # SQLite ìŠ¤í‚¤ë§ˆ
                        self._create_sqlite_tables(conn)
                    # íŠ¸ëœì­ì…˜ì€ with ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ ì»¤ë°‹ë¨
                
                print(f"âœ… {'PostgreSQL' if self.is_postgresql else 'SQLite'} ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
                
        except SQLAlchemyError as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _create_postgresql_tables(self, conn):
        """PostgreSQL í…Œì´ë¸” ìƒì„±"""
        # ì›ë³¸ ì†Œì…œë¯¸ë””ì–´ ê²Œì‹œê¸€ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS social_media_posts (
                id SERIAL PRIMARY KEY,
                platform VARCHAR(50) NOT NULL,
                keyword VARCHAR(200) NOT NULL,
                content TEXT NOT NULL,
                author VARCHAR(100),
                timestamp TIMESTAMP WITH TIME ZONE,
                likes INTEGER DEFAULT 0,
                engagement_metrics JSONB,
                metadata JSONB,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            )
        '''))
        
        # ê°ì„±ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS sentiment_analysis (
                id SERIAL PRIMARY KEY,
                post_id INTEGER REFERENCES social_media_posts(id),
                sentiment VARCHAR(20) NOT NULL,
                confidence REAL NOT NULL,
                scores JSONB,
                analyzed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            )
        '''))
        
        # í‚¤ì›Œë“œ ë¶„ì„ ìš”ì•½ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS keyword_analysis (
                id SERIAL PRIMARY KEY,
                keyword VARCHAR(200) NOT NULL,
                total_posts INTEGER DEFAULT 0,
                positive_count INTEGER DEFAULT 0,
                negative_count INTEGER DEFAULT 0,
                neutral_count INTEGER DEFAULT 0,
                avg_confidence REAL DEFAULT 0,
                analysis_date TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            )
        '''))
        
        # í•«í•œ ì½˜í…ì¸  ì˜ìƒ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS hot_videos (
                id SERIAL PRIMARY KEY,
                keyword VARCHAR(200) NOT NULL,
                video_id VARCHAR(50) NOT NULL,
                title VARCHAR(500) NOT NULL,
                channel VARCHAR(200),
                published_at TIMESTAMP WITH TIME ZONE,
                view_count INTEGER DEFAULT 0,
                like_count INTEGER DEFAULT 0,
                comment_count INTEGER DEFAULT 0,
                hot_score REAL DEFAULT 0,
                thumbnail VARCHAR(500),
                url VARCHAR(500),
                description TEXT,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            )
        '''))
        
        # í•«í•œ ì½˜í…ì¸  ëŒ“ê¸€ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS hot_comments (
                id SERIAL PRIMARY KEY,
                keyword VARCHAR(200) NOT NULL,
                video_id VARCHAR(50) NOT NULL,
                comment_id VARCHAR(50) NOT NULL,
                author VARCHAR(100),
                content TEXT NOT NULL,
                like_count INTEGER DEFAULT 0,
                reply_count INTEGER DEFAULT 0,
                published_at TIMESTAMP WITH TIME ZONE,
                hot_score REAL DEFAULT 0,
                video_title VARCHAR(500),
                video_url VARCHAR(500),
                created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            )
        '''))
        
        # ì¸ë±ìŠ¤ ìƒì„±
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_posts_keyword ON social_media_posts(keyword)'))
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_posts_platform ON social_media_posts(platform)'))
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_sentiment_post ON sentiment_analysis(post_id)'))
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_hot_videos_keyword ON hot_videos(keyword)'))
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_hot_comments_keyword ON hot_comments(keyword)'))
    
    def _create_sqlite_tables(self, conn):
        """SQLite í…Œì´ë¸” ìƒì„±"""
        # ì›ë³¸ ì†Œì…œë¯¸ë””ì–´ ê²Œì‹œê¸€ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS social_media_posts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                platform TEXT NOT NULL,
                keyword TEXT NOT NULL,
                content TEXT NOT NULL,
                author TEXT,
                timestamp TEXT,
                likes INTEGER DEFAULT 0,
                engagement_metrics TEXT,
                metadata TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        '''))
        
        # ê°ì„±ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS sentiment_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                post_id INTEGER,
                sentiment TEXT NOT NULL,
                confidence REAL NOT NULL,
                scores TEXT,
                analyzed_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (post_id) REFERENCES social_media_posts (id)
            )
        '''))
        
        # í‚¤ì›Œë“œ ë¶„ì„ ìš”ì•½ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS keyword_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                keyword TEXT NOT NULL,
                total_posts INTEGER DEFAULT 0,
                positive_count INTEGER DEFAULT 0,
                negative_count INTEGER DEFAULT 0,
                neutral_count INTEGER DEFAULT 0,
                avg_confidence REAL DEFAULT 0,
                analysis_date TEXT DEFAULT CURRENT_TIMESTAMP
            )
        '''))
        
        # í•«í•œ ì½˜í…ì¸  ì˜ìƒ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS hot_videos (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                keyword TEXT NOT NULL,
                video_id TEXT NOT NULL,
                title TEXT NOT NULL,
                channel TEXT,
                published_at TEXT,
                view_count INTEGER DEFAULT 0,
                like_count INTEGER DEFAULT 0,
                comment_count INTEGER DEFAULT 0,
                hot_score REAL DEFAULT 0,
                thumbnail TEXT,
                url TEXT,
                description TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        '''))
        
        # í•«í•œ ì½˜í…ì¸  ëŒ“ê¸€ í…Œì´ë¸”
        conn.execute(text('''
            CREATE TABLE IF NOT EXISTS hot_comments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                keyword TEXT NOT NULL,
                video_id TEXT NOT NULL,
                comment_id TEXT NOT NULL,
                author TEXT,
                content TEXT NOT NULL,
                like_count INTEGER DEFAULT 0,
                reply_count INTEGER DEFAULT 0,
                published_at TEXT,
                hot_score REAL DEFAULT 0,
                video_title TEXT,
                video_url TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        '''))
        
        # ì¸ë±ìŠ¤ ìƒì„±
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_posts_keyword ON social_media_posts(keyword)'))
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_posts_platform ON social_media_posts(platform)'))
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_sentiment_post ON sentiment_analysis(post_id)'))
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_hot_videos_keyword ON hot_videos(keyword)'))
        conn.execute(text('CREATE INDEX IF NOT EXISTS idx_hot_comments_keyword ON hot_comments(keyword)'))
    
    def save_analysis_results(self, keyword: str, analyzed_data: List[Dict[str, Any]]) -> bool:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        
        Args:
            keyword: ë¶„ì„í•œ í‚¤ì›Œë“œ
            analyzed_data: ë¶„ì„ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            with self.engine.connect() as conn:
                with conn.begin():  # íŠ¸ëœì­ì…˜ ì‹œì‘
                    cursor = conn.cursor()
                    
                    post_ids = []
                    sentiment_counts = {'positive': 0, 'negative': 0, 'neutral': 0}
                    total_confidence = 0
                    
                    for item in analyzed_data:
                        # 1. ì›ë³¸ ê²Œì‹œê¸€ ì €ì¥
                        cursor.execute('''
                            INSERT INTO social_media_posts 
                            (platform, keyword, content, author, timestamp, likes, engagement_metrics, metadata)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            item.get('platform', 'unknown'),
                            keyword,
                            item.get('content', ''),
                            item.get('author', 'anonymous'),
                            item.get('timestamp', datetime.now().isoformat()),
                            item.get('likes', 0),
                            json.dumps(item.get('engagement_metrics', {})),
                            json.dumps(item.get('metadata', {}))
                        ))
                        
                        post_id = cursor.lastrowid
                        post_ids.append(post_id)
                        
                        # 2. ê°ì„±ë¶„ì„ ê²°ê³¼ ì €ì¥
                        sentiment = item.get('sentiment', 'neutral')
                        confidence = item.get('confidence', 0.5)
                        scores = item.get('scores', {})
                        
                        cursor.execute('''
                            INSERT INTO sentiment_analysis 
                            (post_id, sentiment, confidence, scores)
                            VALUES (?, ?, ?, ?)
                        ''', (
                            post_id,
                            sentiment,
                            confidence,
                            json.dumps(scores)
                        ))
                        
                        # í†µê³„ ì—…ë°ì´íŠ¸
                        sentiment_counts[sentiment] += 1
                        total_confidence += confidence
                    
                    # 3. í‚¤ì›Œë“œ ë¶„ì„ ìš”ì•½ ì €ì¥
                    avg_confidence = total_confidence / len(analyzed_data) if analyzed_data else 0
                    
                    cursor.execute('''
                        INSERT INTO keyword_analysis 
                        (keyword, total_posts, positive_count, negative_count, neutral_count, avg_confidence)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (
                        keyword,
                        len(analyzed_data),
                        sentiment_counts['positive'],
                        sentiment_counts['negative'],
                        sentiment_counts['neutral'],
                        avg_confidence
                    ))
                    # íŠ¸ëœì­ì…˜ì€ with ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ ì»¤ë°‹ë¨
                
                print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ì— {len(analyzed_data)}ê°œ ë ˆì½”ë“œ ì €ì¥ ì™„ë£Œ")
                return True
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def save_hot_content_results(self, keyword: str, hot_content: Dict[str, Any]) -> bool:
        """í•«í•œ ì½˜í…ì¸  ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            with self.engine.connect() as conn:
                with conn.begin():  # íŠ¸ëœì­ì…˜ ì‹œì‘
                    # ì˜ìƒ ë°ì´í„° ì €ì¥
                    for video in hot_content.get('hot_videos', []):
                        video_query = text("""
                            INSERT INTO hot_videos (
                                keyword, video_id, title, channel, published_at,
                                view_count, like_count, comment_count, hot_score,
                                thumbnail, url, description, created_at
                            ) VALUES (
                                :keyword, :video_id, :title, :channel, :published_at,
                                :view_count, :like_count, :comment_count, :hot_score,
                                :thumbnail, :url, :description, :created_at
                            )
                        """)
                        
                        conn.execute(video_query, {
                            'keyword': keyword,
                            'video_id': video['video_id'],
                            'title': video['title'],
                            'channel': video['channel'],
                            'published_at': video['published_at'],
                            'view_count': video['view_count'],
                            'like_count': video['like_count'],
                            'comment_count': video['comment_count'],
                            'hot_score': video['hot_score'],
                            'thumbnail': video['thumbnail'],
                            'url': video['url'],
                            'description': video['description'],
                            'created_at': datetime.now().isoformat()
                        })
                    
                    # ëŒ“ê¸€ ë°ì´í„° ì €ì¥
                    for comment in hot_content.get('hot_comments', []):
                        comment_query = text("""
                            INSERT INTO hot_comments (
                                keyword, video_id, comment_id, author, content,
                                like_count, reply_count, published_at, hot_score,
                                video_title, video_url, created_at
                            ) VALUES (
                                :keyword, :video_id, :comment_id, :author, :content,
                                :like_count, :reply_count, :published_at, :hot_score,
                                :video_title, :video_url, :created_at
                            )
                        """)
                        
                        conn.execute(comment_query, {
                            'keyword': keyword,
                            'video_id': comment['video_id'],
                            'comment_id': comment['comment_id'],
                            'author': comment['author'],
                            'content': comment['content'],
                            'like_count': comment['like_count'],
                            'reply_count': comment['reply_count'],
                            'published_at': comment['published_at'],
                            'hot_score': comment['hot_score'],
                            'video_title': comment['video_title'],
                            'video_url': comment['video_url'],
                            'created_at': datetime.now().isoformat()
                        })
                    # íŠ¸ëœì­ì…˜ì€ with ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ ì»¤ë°‹ë¨
                
                return True
                
        except SQLAlchemyError as e:
            logger.error(f"Error saving hot content results: {e}")
            return False
    
    def delete_keyword_data(self, keyword: str) -> bool:
        """íŠ¹ì • í‚¤ì›Œë“œì˜ ë°ì´í„° ì‚­ì œ"""
        try:
            with self.engine.connect() as conn:
                with conn.begin():  # íŠ¸ëœì­ì…˜ ì‹œì‘
                    # ì˜ìƒ ë°ì´í„° ì‚­ì œ
                    conn.execute(text("DELETE FROM hot_videos WHERE keyword = :keyword"), 
                               {'keyword': keyword})
                    
                    # ëŒ“ê¸€ ë°ì´í„° ì‚­ì œ
                    conn.execute(text("DELETE FROM hot_comments WHERE keyword = :keyword"), 
                               {'keyword': keyword})
                    # íŠ¸ëœì­ì…˜ì€ with ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ ì»¤ë°‹ë¨
                
                return True
                
        except SQLAlchemyError as e:
            logger.error(f"Error deleting keyword data: {e}")
            return False
    
    def cleanup_old_data(self, cutoff_date: datetime) -> bool:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        try:
            with self.engine.connect() as conn:
                with conn.begin():  # íŠ¸ëœì­ì…˜ ì‹œì‘
                    cutoff_str = cutoff_date.isoformat()
                    
                    # ì˜¤ë˜ëœ ì˜ìƒ ë°ì´í„° ì‚­ì œ
                    conn.execute(text("DELETE FROM hot_videos WHERE created_at < :cutoff"), 
                               {'cutoff': cutoff_str})
                    
                    # ì˜¤ë˜ëœ ëŒ“ê¸€ ë°ì´í„° ì‚­ì œ
                    conn.execute(text("DELETE FROM hot_comments WHERE created_at < :cutoff"), 
                               {'cutoff': cutoff_str})
                    # íŠ¸ëœì­ì…˜ì€ with ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ ì»¤ë°‹ë¨
                
                return True
                
        except SQLAlchemyError as e:
            logger.error(f"Error cleaning up old data: {e}")
            return False
    
    def get_stored_hot_content(self, keyword: str = None) -> Dict[str, Any]:
        """ì €ì¥ëœ í•«í•œ ì½˜í…ì¸  ì¡°íšŒ"""
        try:
            with self.engine.connect() as conn:
                # ì˜ìƒ ë°ì´í„° ì¡°íšŒ
                video_query = "SELECT * FROM hot_videos"
                params = {}
                
                if keyword:
                    video_query += " WHERE keyword = :keyword"
                    params['keyword'] = keyword
                
                video_query += " ORDER BY hot_score DESC"
                
                videos_result = conn.execute(text(video_query), params)
                videos = [dict(row._mapping) for row in videos_result]
                
                # ëŒ“ê¸€ ë°ì´í„° ì¡°íšŒ  
                comment_query = "SELECT * FROM hot_comments"
                
                if keyword:
                    comment_query += " WHERE keyword = :keyword"
                
                comment_query += " ORDER BY hot_score DESC"
                
                comments_result = conn.execute(text(comment_query), params)
                comments = [dict(row._mapping) for row in comments_result]
                
                return {
                    'hot_videos': videos,
                    'hot_comments': comments,
                    'keyword': keyword,
                    'total_videos': len(videos),
                    'total_comments': len(comments)
                }
                
        except SQLAlchemyError as e:
            logger.error(f"Error getting stored hot content: {e}")
            return {'hot_videos': [], 'hot_comments': [], 'keyword': keyword}
    
    def get_last_collection_time(self) -> str:
        """ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œê°„ ì¡°íšŒ"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text("""
                    SELECT MAX(created_at) as last_time 
                    FROM hot_videos
                """))
                
                row = result.fetchone()
                if row and row[0]:
                    # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    last_time = row[0]
                    if isinstance(last_time, datetime):
                        return last_time.strftime("%Y-%m-%d %H:%M:%S")
                    else:
                        return str(last_time)
                return "ìˆ˜ì§‘ ê¸°ë¡ ì—†ìŒ"
                
        except SQLAlchemyError as e:
            logger.error(f"Error getting last collection time: {e}")
            return "ì¡°íšŒ ì‹¤íŒ¨"
    
    def get_total_stored_videos(self) -> int:
        """ì €ì¥ëœ ì´ ì˜ìƒ ìˆ˜"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text("SELECT COUNT(*) FROM hot_videos"))
                return result.fetchone()[0]
                
        except SQLAlchemyError as e:
            logger.error(f"Error getting total stored videos: {e}")
            return 0
    
    def get_total_stored_comments(self) -> int:
        """ì €ì¥ëœ ì´ ëŒ“ê¸€ ìˆ˜"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text("SELECT COUNT(*) FROM hot_comments"))
                return result.fetchone()[0]
                
        except SQLAlchemyError as e:
            logger.error(f"Error getting total stored comments: {e}")
            return 0

    def get_keywords_stats(self) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œë³„ í†µê³„ ì¡°íšŒ"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text("""
                    SELECT 
                        keyword,
                        COUNT(*) as video_count,
                        AVG(hot_score) as avg_hot_score,
                        MAX(created_at) as last_update
                    FROM hot_videos
                    GROUP BY keyword
                    ORDER BY avg_hot_score DESC
                """))
                
                # datetime í•„ë“œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                stats = []
                for row in result:
                    row_dict = dict(row._mapping)
                    if row_dict.get('last_update') and isinstance(row_dict['last_update'], datetime):
                        row_dict['last_update'] = row_dict['last_update'].strftime("%Y-%m-%d %H:%M:%S")
                    stats.append(row_dict)
                
                return stats
                
        except SQLAlchemyError as e:
            logger.error(f"Error getting keywords stats: {e}")
            return []
    
    def get_keyword_history(self, keyword: str, limit: int = 10) -> pd.DataFrame:
        """í‚¤ì›Œë“œ ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
        
        Args:
            keyword: ì¡°íšŒí•  í‚¤ì›Œë“œ
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜
            
        Returns:
            ë¶„ì„ íˆìŠ¤í† ë¦¬ ë°ì´í„°í”„ë ˆì„
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = '''
                    SELECT * FROM keyword_analysis 
                    WHERE keyword = ? 
                    ORDER BY analysis_date DESC 
                    LIMIT ?
                '''
                df = pd.read_sql_query(query, conn, params=(keyword, limit))
                return df
                
        except Exception as e:
            print(f"âŒ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def get_recent_posts(self, keyword: str = None, limit: int = 50) -> pd.DataFrame:
        """ìµœê·¼ ê²Œì‹œê¸€ ì¡°íšŒ
        
        Args:
            keyword: í‚¤ì›Œë“œ í•„í„° (Noneì´ë©´ ì „ì²´)
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜
            
        Returns:
            ê²Œì‹œê¸€ ë°ì´í„°í”„ë ˆì„
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                if keyword:
                    query = '''
                        SELECT p.*, s.sentiment, s.confidence 
                        FROM social_media_posts p
                        LEFT JOIN sentiment_analysis s ON p.id = s.post_id
                        WHERE p.keyword = ?
                        ORDER BY p.created_at DESC 
                        LIMIT ?
                    '''
                    params = (keyword, limit)
                else:
                    query = '''
                        SELECT p.*, s.sentiment, s.confidence 
                        FROM social_media_posts p
                        LEFT JOIN sentiment_analysis s ON p.id = s.post_id
                        ORDER BY p.created_at DESC 
                        LIMIT ?
                    '''
                    params = (limit,)
                
                df = pd.read_sql_query(query, conn, params=params)
                return df
                
        except Exception as e:
            print(f"âŒ ê²Œì‹œê¸€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def get_sentiment_trends(self, keyword: str, days: int = 7) -> pd.DataFrame:
        """ê°ì„± íŠ¸ë Œë“œ ì¡°íšŒ
        
        Args:
            keyword: í‚¤ì›Œë“œ
            days: ì¡°íšŒí•  ì¼ìˆ˜
            
        Returns:
            íŠ¸ë Œë“œ ë°ì´í„°í”„ë ˆì„
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = '''
                    SELECT 
                        DATE(p.created_at) as date,
                        s.sentiment,
                        COUNT(*) as count,
                        AVG(s.confidence) as avg_confidence
                    FROM social_media_posts p
                    JOIN sentiment_analysis s ON p.id = s.post_id
                    WHERE p.keyword = ? AND DATE(p.created_at) >= DATE('now', '-{} days')
                    GROUP BY DATE(p.created_at), s.sentiment
                    ORDER BY date DESC
                '''.format(days)
                
                df = pd.read_sql_query(query, conn, params=(keyword,))
                return df
                
        except Exception as e:
            print(f"âŒ íŠ¸ë Œë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def get_top_keywords(self, limit: int = 10) -> pd.DataFrame:
        """ì¸ê¸° í‚¤ì›Œë“œ ì¡°íšŒ
        
        Args:
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜
            
        Returns:
            ì¸ê¸° í‚¤ì›Œë“œ ë°ì´í„°í”„ë ˆì„
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = '''
                    SELECT 
                        keyword,
                        SUM(total_posts) as total_posts,
                        AVG(avg_confidence) as avg_confidence,
                        MAX(analysis_date) as last_analysis
                    FROM keyword_analysis
                    GROUP BY keyword
                    ORDER BY total_posts DESC
                    LIMIT ?
                '''
                
                df = pd.read_sql_query(query, conn, params=(limit,))
                return df
                
        except Exception as e:
            print(f"âŒ ì¸ê¸° í‚¤ì›Œë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def clean_old_data(self, days: int = 30) -> bool:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
        
        Args:
            days: ë³´ê´€í•  ì¼ìˆ˜
            
        Returns:
            ì •ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        try:
            with self.engine.connect() as conn:
                with conn.begin():  # íŠ¸ëœì­ì…˜ ì‹œì‘
                    # ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ (SQLAlchemy text ì‚¬ìš©)
                    conn.execute(text('''
                        DELETE FROM sentiment_analysis 
                        WHERE post_id IN (
                            SELECT id FROM social_media_posts 
                            WHERE DATE(created_at) < DATE('now', '-{} days')
                        )
                    '''.format(days)))
                    
                    conn.execute(text('''
                        DELETE FROM social_media_posts 
                        WHERE DATE(created_at) < DATE('now', '-{} days')
                    '''.format(days)))
                    
                    conn.execute(text('''
                        DELETE FROM keyword_analysis 
                        WHERE DATE(analysis_date) < DATE('now', '-{} days')
                    '''.format(days)))
                    # íŠ¸ëœì­ì…˜ì€ with ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ ì»¤ë°‹ë¨
                
                print(f"âœ… {days}ì¼ ì´ì „ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
                return True
                
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def get_database_stats(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ
        
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜
                cursor.execute('SELECT COUNT(*) FROM social_media_posts')
                posts_count = cursor.fetchone()[0]
                
                cursor.execute('SELECT COUNT(*) FROM sentiment_analysis')
                analysis_count = cursor.fetchone()[0]
                
                cursor.execute('SELECT COUNT(DISTINCT keyword) FROM keyword_analysis')
                keywords_count = cursor.fetchone()[0]
                
                # ìµœê·¼ ë¶„ì„ì¼
                cursor.execute('SELECT MAX(created_at) FROM social_media_posts')
                last_post = cursor.fetchone()[0]
                
                return {
                    'total_posts': posts_count,
                    'total_analysis': analysis_count,
                    'unique_keywords': keywords_count,
                    'last_post_date': last_post,
                    'database_size': os.path.getsize(self.db_path) if os.path.exists(self.db_path) else 0
                }
                
        except Exception as e:
            print(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

# ì‚¬ìš© ì˜ˆì‹œ (í…ŒìŠ¤íŠ¸ìš©)
if __name__ == "__main__":
    db = DatabaseManager()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_data = [
        {
            'platform': 'YouTube',
            'content': 'ì‚¼ì„± ê°¤ëŸ­ì‹œ ì •ë§ ì¢‹ë„¤ìš”!',
            'author': 'TestUser1',
            'sentiment': 'positive',
            'confidence': 0.9,
            'scores': {'positive': 0.9, 'negative': 0.05, 'neutral': 0.05}
        }
    ]
    
    # ì €ì¥ í…ŒìŠ¤íŠ¸
    success = db.save_analysis_results('ì‚¼ì„± ê°¤ëŸ­ì‹œ', test_data)
    print(f"ì €ì¥ ì„±ê³µ: {success}")
    
    # ì¡°íšŒ í…ŒìŠ¤íŠ¸
    stats = db.get_database_stats()
    print(f"ë°ì´í„°ë² ì´ìŠ¤ í†µê³„: {stats}") 