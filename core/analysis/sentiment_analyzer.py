import os
import re
from typing import Dict, Any, List
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np

class SentimentAnalyzer:
    """ê°ì„±ë¶„ì„ ì—”ì§„
    
    ë‚˜ì¤‘ì— FastAPIë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë•Œë„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë…ë¦½ì ì¸ ëª¨ë“ˆ
    """
    
    def __init__(self, model_name: str = None):
        """ê°ì„±ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ëª…. Noneì´ë©´ ê¸°ë³¸ í•œêµ­ì–´ ëª¨ë¸ ì‚¬ìš©
        """
        self.model_name = model_name or "matthewburke/korean-sentiment-analysis-dataset"
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        try:
            print(f"ğŸ§  ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘... ({self.model_name})")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
            self.model.to(self.device)
            self.model.eval()
            print("âœ… ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            self.model_loaded = True
            
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            print("ğŸ“ ê·œì¹™ ê¸°ë°˜ ê°ì„±ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.model_loaded = False
    
    def analyze(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ê°ì„±ë¶„ì„
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            ê°ì„±ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not text or not text.strip():
            return {
                'sentiment': 'neutral',
                'confidence': 0.5,
                'scores': {'positive': 0.33, 'negative': 0.33, 'neutral': 0.34}
            }
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        cleaned_text = self._preprocess_text(text)
        
        if self.model_loaded:
            return self._analyze_with_model(cleaned_text)
        else:
            return self._analyze_with_rules(cleaned_text)
    
    def _analyze_with_model(self, text: str) -> Dict[str, Any]:
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°ì„±ë¶„ì„
        
        Args:
            text: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
            
        Returns:
            ê°ì„±ë¶„ì„ ê²°ê³¼
        """
        try:
            # í† í¬ë‚˜ì´ì§•
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                truncation=True,
                max_length=512,
                padding=True
            )
            inputs = {key: value.to(self.device) for key, value in inputs.items()}
            
            # ì˜ˆì¸¡
            with torch.no_grad():
                outputs = self.model(**inputs)
                probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
                probabilities = probabilities.cpu().numpy()[0]
            
            # ë ˆì´ë¸” ë§¤í•‘ (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            labels = ['negative', 'positive']  # ëŒ€ë¶€ë¶„ì˜ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸
            if len(probabilities) == 3:
                labels = ['negative', 'neutral', 'positive']
            
            # ê²°ê³¼ ì •ë¦¬
            scores = {label: float(prob) for label, prob in zip(labels, probabilities)}
            predicted_sentiment = labels[np.argmax(probabilities)]
            confidence = float(np.max(probabilities))
            
            # neutralì´ ì—†ëŠ” ëª¨ë¸ì˜ ê²½ìš° ì„ê³„ê°’ìœ¼ë¡œ neutral íŒë‹¨
            if len(labels) == 2 and confidence < 0.8:
                predicted_sentiment = 'neutral'
                scores['neutral'] = 1.0 - confidence
                confidence = scores['neutral']
            
            return {
                'sentiment': predicted_sentiment,
                'confidence': confidence,
                'scores': scores
            }
            
        except Exception as e:
            print(f"ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._analyze_with_rules(text)
    
    def _analyze_with_rules(self, text: str) -> Dict[str, Any]:
        """ê·œì¹™ ê¸°ë°˜ ê°ì„±ë¶„ì„ (ëª¨ë¸ì´ ì—†ì„ ë•Œ ëŒ€ì•ˆ)
        
        Args:
            text: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
            
        Returns:
            ê°ì„±ë¶„ì„ ê²°ê³¼
        """
        # ê¸ì • í‚¤ì›Œë“œ
        positive_keywords = [
            'ì¢‹', 'í›Œë¥­', 'ìµœê³ ', 'ì™„ë²½', 'ëŒ€ë°•', 'êµ¿', 'ì¢‹ì•„', 'ë§Œì¡±', 'ì¶”ì²œ',
            'ê°ì‚¬', 'ê³ ë§ˆ', 'ë†€ë¼', 'ì‹ ë‚˜', 'ê¸°ì˜', 'í–‰ë³µ', 'ì‚¬ë‘', 'ì¢‹ë„¤',
            'ë©‹ì§€', 'í™˜ìƒ', 'ì™„ì „', 'ì •ë§', 'ì§„ì§œ', 'ì˜ˆì˜', 'ì•„ë¦„ë‹¤', 'ë‹¬ì½¤',
            'ë§›ìˆ', 'ì‹œì›', 'í¸ë¦¬', 'ìœ ìš©', 'ë„ì›€'
        ]
        
        # ë¶€ì • í‚¤ì›Œë“œ  
        negative_keywords = [
            'ë³„ë¡œ', 'ë‚˜ì˜', 'ì‹«', 'ì‹¤ë§', 'ìµœì•…', 'ë”ì°', 'ì§œì¦', 'í™”ë‚˜', 'ë¯¸ì›Œ',
            'ìŠ¬í”„', 'ìš°ìš¸', 'ê±±ì •', 'ë¶ˆì•ˆ', 'ë¬´ì„œ', 'ì•„ì‰½', 'í›„íšŒ', 'ë¹„ì‹¸',
            'ì–´ë ¤', 'ë³µì¡', 'ë¶ˆí¸', 'ëŠë¦¬', 'ë”ëŸ¬', 'ëª»ìƒ', 'ë§›ì—†', 'ì•„í”„',
            'ì§€ê²¨', 'í˜ë“¤', 'í”¼ê³¤', 'ê·€ì°®'
        ]
        
        # ì ìˆ˜ ê³„ì‚°
        positive_score = sum(1 for keyword in positive_keywords if keyword in text)
        negative_score = sum(1 for keyword in negative_keywords if keyword in text)
        
        # ê°ì„± íŒë‹¨
        total_score = positive_score + negative_score
        
        if total_score == 0:
            sentiment = 'neutral'
            confidence = 0.5
            scores = {'positive': 0.33, 'negative': 0.33, 'neutral': 0.34}
        else:
            pos_ratio = positive_score / total_score
            neg_ratio = negative_score / total_score
            
            if pos_ratio > neg_ratio:
                sentiment = 'positive'
                confidence = min(0.9, 0.5 + pos_ratio * 0.4)
                scores = {
                    'positive': confidence,
                    'negative': (1 - confidence) * 0.3,
                    'neutral': (1 - confidence) * 0.7
                }
            elif neg_ratio > pos_ratio:
                sentiment = 'negative'  
                confidence = min(0.9, 0.5 + neg_ratio * 0.4)
                scores = {
                    'negative': confidence,
                    'positive': (1 - confidence) * 0.3,
                    'neutral': (1 - confidence) * 0.7
                }
            else:
                sentiment = 'neutral'
                confidence = 0.6
                scores = {'positive': 0.3, 'negative': 0.3, 'neutral': 0.6}
        
        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'scores': scores
        }
    
    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
        """
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        
        # URL ì œê±°
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±ë§Œ ìœ ì§€)
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', text)
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        return text
    
    def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë°°ì¹˜ ë¶„ì„
        
        Args:
            texts: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê°ì„±ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        for text in texts:
            result = self.analyze(text)
            results.append(result)
        
        return results
    
    def get_emotion_details(self, text: str) -> Dict[str, Any]:
        """ì„¸ë¶€ ê°ì • ë¶„ì„ (í™•ì¥ ê¸°ëŠ¥)
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            ì„¸ë¶€ ê°ì • ë¶„ì„ ê²°ê³¼
        """
        # ê¸°ë³¸ ê°ì„±ë¶„ì„
        basic_sentiment = self.analyze(text)
        
        # ê°ì •ë³„ í‚¤ì›Œë“œ (ê°„ë‹¨í•œ ë²„ì „)
        emotions = {
            'joy': ['ê¸°ì˜', 'í–‰ë³µ', 'ì‹ ë‚˜', 'ì¢‹ì•„', 'ì¦ê±°', 'ì›ƒ', 'ã…ã…', 'ã…‹ã…‹'],
            'anger': ['í™”ë‚˜', 'ì§œì¦', 'ë¶„ë…¸', 'ì—´ë°›', 'ë¹¡', 'ë¯¸ì¹˜'],
            'sadness': ['ìŠ¬í”„', 'ìš°ìš¸', 'ëˆˆë¬¼', 'ã… ã… ', 'ì†ìƒ', 'ì„œëŸ¬'],
            'fear': ['ë¬´ì„œ', 'ë‘ë ¤', 'ê±±ì •', 'ë¶ˆì•ˆ', 'ë–¨ë ¤'],
            'surprise': ['ë†€ë¼', 'í—‰', 'ì™€', 'ëŒ€ë°•', 'ì–´ë¨¸'],
            'disgust': ['ì—­ê²¹', 'ë”ëŸ¬', 'ì‹«ì–´', 'í˜ì˜¤', 'ì§•ê·¸']
        }
        
        emotion_scores = {}
        for emotion, keywords in emotions.items():
            score = sum(1 for keyword in keywords if keyword in text) / len(keywords)
            emotion_scores[emotion] = min(1.0, score)
        
        # ì£¼ëœ ê°ì • ì°¾ê¸°
        main_emotion = max(emotion_scores.items(), key=lambda x: x[1])
        
        return {
            'basic_sentiment': basic_sentiment,
            'emotions': emotion_scores,
            'main_emotion': main_emotion[0],
            'emotion_confidence': main_emotion[1]
        }

# ì‚¬ìš© ì˜ˆì‹œ (í…ŒìŠ¤íŠ¸ìš©)
if __name__ == "__main__":
    analyzer = SentimentAnalyzer()
    
    test_texts = [
        "ì‚¼ì„± ê°¤ëŸ­ì‹œ ì •ë§ ì¢‹ë„¤ìš”! ì¶”ì²œí•©ë‹ˆë‹¤.",
        "ì•„ì´í°ì´ ë³„ë¡œì—ìš”... ì‹¤ë§ì…ë‹ˆë‹¤.",
        "ì´ ì œí’ˆ ì–´ë–¤ê°€ìš”? ê¶ê¸ˆí•©ë‹ˆë‹¤."
    ]
    
    for text in test_texts:
        result = analyzer.analyze(text)
        print(f"í…ìŠ¤íŠ¸: {text}")
        print(f"ê°ì„±: {result['sentiment']} (ì‹ ë¢°ë„: {result['confidence']:.2f})")
        print("---") 