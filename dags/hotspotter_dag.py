"""
HotSpotter ìë™ ìˆ˜ì§‘ Airflow DAG
YouTube í•«í•œ ì½˜í…ì¸ ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ” ì›Œí¬í”Œë¡œìš°
"""
# pylint: disable=pointless-statement

import os
import sys
from datetime import datetime, timedelta
from dotenv import load_dotenv

from airflow import DAG
from airflow.operators.empty import EmptyOperator
from airflow.operators.python import PythonOperator

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€ (ë™ì  ê²½ë¡œ)
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)  # dags í´ë”ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬
sys.path.append(project_root)

# .env íŒŒì¼ ë¡œë“œ (python-dotenv ì‚¬ìš©)
dotenv_path = os.path.join(project_root, '.env')
if os.path.exists(dotenv_path):
    load_dotenv(dotenv_path)
    print(f"âœ… .env íŒŒì¼ ë¡œë“œ ì„±ê³µ: {dotenv_path}")
else:
    print(f"âš ï¸ .env íŒŒì¼ ì—†ìŒ: {dotenv_path}")

print(f"DAG ë¡œë”©: í”„ë¡œì íŠ¸ ë£¨íŠ¸ = {project_root}")  # ë””ë²„ê¹…ìš©


#system path ì„¤ì • ì´í›„ì— í•´ì•¼ ì˜¤ë¥˜ ì•ˆ ë‚˜ì˜´
from config.keywords import COLLECTION_SETTINGS, TARGET_KEYWORDS, KEYWORD_SPECIFIC_SETTINGS
from core.collectors.youtube_collector import YouTubeCollector
from core.database.database_manager import DatabaseManager



# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'hotspotter',
    'depends_on_past': False,
    'start_date': datetime(2025, 7, 25),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
    'catchup': True,  # ê³¼ê±° ì‹¤í–‰ ê±´ë„ˆë›°ê¸°
}

# DAG ì •ì˜
dag = DAG(
    'hotspotter_collection',
    default_args=default_args,
    description='YouTube í•«í•œ ì½˜í…ì¸  ìë™ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸',
    schedule_interval=timedelta(hours=COLLECTION_SETTINGS.get("collection_interval_hours")),  # 1ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
    max_active_runs=1,  # ë™ì‹œ ì‹¤í–‰ ë°©ì§€
    tags=['youtube', 'hotspotter', 'data-collection'],
)

def collect_keyword_data(keyword: str, **context):
    """íŠ¹ì • í‚¤ì›Œë“œì˜ í•«í•œ ì½˜í…ì¸  ìˆ˜ì§‘"""
    print(f"ğŸ” í‚¤ì›Œë“œ '{keyword}' ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    try:
        # YouTube ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        collector = YouTubeCollector()
        db_manager = DatabaseManager()
        
        # í‚¤ì›Œë“œë³„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        keyword_settings = KEYWORD_SPECIFIC_SETTINGS.get(keyword, {})
        max_videos = keyword_settings.get("max_videos", COLLECTION_SETTINGS["max_videos_per_keyword"])
        
        # í•«í•œ ì½˜í…ì¸  ìˆ˜ì§‘
        hot_content = collector.find_hot_content(keyword, max_videos)
        
        # API ì˜¤ë¥˜ ìƒíƒœ í™•ì¸
        status = hot_content.get('status')
        if status in ['api_error', 'unexpected_error']:
            error_msg = hot_content.get('message', 'Unknown error')
            
            # í• ë‹¹ëŸ‰ ì´ˆê³¼ íŠ¹ë³„ ì²˜ë¦¬
            if 'quotaExceeded' in error_msg or 'quota' in error_msg.lower():
                raise Exception(f"YouTube API ì¼ì¼ í• ë‹¹ëŸ‰ ì´ˆê³¼\n"
                              f"ìƒì„¸: {error_msg}")
            
            # ê¸°íƒ€ API ì˜¤ë¥˜
            elif status == 'api_error':
                raise Exception(f"YouTube API ì˜¤ë¥˜: {keyword}\nìƒì„¸: {error_msg}")
            
            # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
            else:
                raise Exception(f"=ìˆ˜ì§‘ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {keyword}\nìƒì„¸: {error_msg}")
        
        # ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê²½ê³  ì²˜ë¦¬
        video_count = len(hot_content.get('hot_videos', []))
        comment_count = len(hot_content.get('hot_comments', []))
        
        if video_count == 0 and comment_count == 0:
            print(f"'{keyword}' ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")
            print(f"ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸: 1) í•«ì ìˆ˜ ê¸°ì¤€(45ì ) ë¯¸ë‹¬, 2) ìµœê·¼ 14ì¼ ë‚´ ì½˜í…ì¸  ë¶€ì¡±, 3) API ì œí•œ")
            # ë°ì´í„°ê°€ ì—†ì–´ë„ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬í•˜ì§€ ì•Šê³  ê²½ê³ ë§Œ ì¶œë ¥
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ìµœì‹  ë°ì´í„°ë¡œ êµì²´)
        db_manager.delete_keyword_data(keyword)
        
        # ìƒˆë¡œìš´ ë°ì´í„° ì €ì¥
        success = db_manager.save_hot_content_results(keyword, hot_content)
        
        if success:
            print(f"âœ… '{keyword}' ìˆ˜ì§‘ ì™„ë£Œ: {video_count}ê°œ ì˜ìƒ, {comment_count}ê°œ ëŒ“ê¸€")
            
            # XComì— ê²°ê³¼ ì €ì¥ (ë‹¤ìŒ íƒœìŠ¤í¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
            return {
                'keyword': keyword,
                'video_count': video_count,
                'comment_count': comment_count,
                'status': 'success'
            }
        else:
            raise Exception(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {keyword}")
            
    except Exception as e:
        print(f"âŒ '{keyword}' ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise

def cleanup_old_data(**context):
    """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
    print("ğŸ§¹ ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì‹œì‘...")
    
    try:
        db_manager = DatabaseManager()
        
        # 7ì¼ ì´ì „ ë°ì´í„° ì‚­ì œ
        cutoff_date = datetime.now() - timedelta(days=COLLECTION_SETTINGS["data_retention_days"])
        
        success = db_manager.cleanup_old_data(cutoff_date)
        
        if success:
            print(f"âœ… {COLLECTION_SETTINGS['data_retention_days']}ì¼ ì´ì „ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
            return {'status': 'success', 'cutoff_date': cutoff_date.isoformat()}
        else:
            raise Exception("ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise

def generate_collection_report(**context):
    """ìˆ˜ì§‘ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
    print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±...")
    
    try:
        db_manager = DatabaseManager()
        
        # ì „ì²´ í†µê³„
        total_videos = db_manager.get_total_stored_videos()
        total_comments = db_manager.get_total_stored_comments()
        last_collection = db_manager.get_last_collection_time()
        
        # í‚¤ì›Œë“œë³„ í†µê³„
        keywords_stats = db_manager.get_keywords_stats()
        
        print("ğŸ“ˆ ìˆ˜ì§‘ ë¦¬í¬íŠ¸:")
        print(f"  ì „ì²´ ì˜ìƒ: {total_videos}ê°œ")
        print(f"  ì „ì²´ ëŒ“ê¸€: {total_comments}ê°œ")
        print(f"  ë§ˆì§€ë§‰ ìˆ˜ì§‘: {last_collection}")
        
        for stat in keywords_stats:
            print(f"  ğŸ“Š {stat['keyword']}: {stat['video_count']}ê°œ ì˜ìƒ, "
                  f"í‰ê·  í•«ì ìˆ˜ {stat['avg_hot_score']:.1f}")
        
        return {
            'total_videos': total_videos,
            'total_comments': total_comments,
            'keywords_stats': keywords_stats
        }
        
    except Exception as e:
        print(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise

# Task ì •ì˜
start_task = EmptyOperator(
    task_id='start_collection',
    dag=dag,
)

# ê° í‚¤ì›Œë“œë³„ ìˆ˜ì§‘ íƒœìŠ¤í¬ (ë³‘ë ¬ ì‹¤í–‰)
collection_tasks = []
for keyword in TARGET_KEYWORDS:
    # task_idì—ì„œ ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½ (ì•ˆì „ì¥ì¹˜)
    safe_keyword = keyword.lower().replace(' ', '_').replace('-', '_')
    # ì˜ìˆ«ìì™€ ì–¸ë”ìŠ¤ì½”ì–´ë§Œ ë‚¨ê¸°ê¸°
    safe_keyword = ''.join(c if c.isalnum() or c == '_' else '_' for c in safe_keyword)
    
    task = PythonOperator(
        task_id=f'collect_{safe_keyword}',
        python_callable=collect_keyword_data,
        op_kwargs={'keyword': keyword},  # ì›ë³¸ í‚¤ì›Œë“œëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬
        dag=dag,
    )
    collection_tasks.append(task)

# ë°ì´í„° ì •ë¦¬ íƒœìŠ¤í¬
cleanup_task = PythonOperator(
    task_id='cleanup_old_data',
    python_callable=cleanup_old_data,
    dag=dag,
)

# ë¦¬í¬íŠ¸ ìƒì„± íƒœìŠ¤í¬
report_task = PythonOperator(
    task_id='generate_report',
    python_callable=generate_collection_report,
    dag=dag,
)

end_task = EmptyOperator(
    task_id='end_collection',
    dag=dag,
)

# Task ì˜ì¡´ì„± ì„¤ì •
start_task >> collection_tasks >> cleanup_task >> report_task >> end_task 

